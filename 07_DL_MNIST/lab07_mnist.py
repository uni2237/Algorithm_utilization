# -*- coding: utf-8 -*-
"""lab07_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f1YQWLMrdyl_Mgtr-rjN5_thbZgAnOAu
"""

import pandas as pd
import numpy as np
import torch 
from torch import nn,optim

from google.colab import files
uploaded=files.upload()
import io

train=pd.read_csv(io.StringIO(uploaded['train.csv'].decode('utf-8')))

uploaded=files.upload()
test=pd.read_csv(io.StringIO(uploaded['test.csv'].decode('utf-8')))

batch =128
lr=0.001
epoch=10

train.head(6)

test.head(6)

y_train=train['label']
x_train=train.drop('label',axis=1)
y_train=pd.get_dummies(y_train) #원핫인코딩
y_train=y_train.to_numpy()
x_train=x_train.to_numpy() #둘다 numpy형태로 저장

x_train

y_train

from sklearn.preprocessing import MinMaxScaler

scaler=MinMaxScaler()

x_train=scaler.fit_transform(x_train)

x_test=test.to_numpy()
x_test=scaler.fit_transform(x_test)

def get_acc(pred,answer):
  correct=0
  for p,a in zip(pred,answer):
    pv,pi=p.max(0)
    av,ai=a.max(0)
    if pi==ai:
      correct+=1
  return correct/len(pred)

class MNISTModel(nn.Module):
  def __init__(self):
    super(MNISTModel,self).__init__()
    self.fc1=nn.Linear(784,512)
    self.fc2=nn.Linear(512,512)
    self.fc3=nn.Linear(512,10)
   

  def forward(self,x):
    x1=torch.relu(self.fc1(x))
    x2=torch.relu(self.fc2(x1))
    x3=self.fc3(x2)
    return x3

#Train
#model 셋팅
def train(x_train,y_train,batch,Ir,epoch):
  model=MNISTModel()
  model.train()

  loss_function=nn.MSELoss(reduction="mean")
  optimizer=optim.Adam(model.parameters(),lr=lr)

  #data 처리
  x=torch.from_numpy(x_train).float()
  y=torch.from_numpy(y_train).float()

  data_loader=torch.utils.data.DataLoader(list(zip(x,y)),batch,shuffle=True)

  epoch_loss=[]
  epoch_acc=[]

  for e in range(epoch):
    total_loss=0
    total_acc=0
    for data in data_loader:
      x_data,y_data=data

      #forward 문제풀이
      pred=model(x_data)

      #backward 채점 및 학습
      loss=loss_function(pred,y_data)
      optimizer.zero_grad()
      loss.backward()

      #update 학습 반영
      optimizer.step()

      total_loss +=loss.item()
      total_acc+=get_acc(pred,y_data)

    epoch_loss.append(total_loss/len(data_loader))
    epoch_acc.append(total_acc/len(data_loader))
    print("Epoch [%d Loss: %.3f\tAcc: %.3f" % (e+1,epoch_loss[e],epoch_acc[e]))
  return model,epoch_loss,epoch_acc

def test(model,x_test,batch):
  model.eval()

  x=torch.from_numpy(x_test).float()
  data_loader=torch.utils.data.DataLoader(x,batch,shuffle=False)

  preds=[]
  for data in data_loader:
    pred=model(data)
    for p in pred:
      pv,pi=p.max(0)
      preds.append(pi.item())
  return preds

model,epoch_loss,epoch_acc=train(x_train,y_train,batch,lr,epoch)
test(model,x_test,batch)

epoch_loss #epoch_acc

import matplotlib.pyplot as plt
import matplotlib

fig=plt.figure()
plt.plot(range(epoch),epoch_loss,label='Loss',color='Pink')
plt.xlabel('Epoch per Loss')
plt.show()

fig=plt.figure()
plt.plot(range(epoch),epoch_acc,label='Accuracy',color='pink')
plt.xlabel('Epoch per Accuracy')
plt.show()

preds=test(model,x_test,batch)
len(preds)

submissions=pd.DataFrame({'ImageId':list(range(1,len(preds)+1)),
                         "Label":preds})
submissions.to_csv("uni_mnist.csv",index=False,header=True)

